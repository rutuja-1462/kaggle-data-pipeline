{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1D_uZg04Cyde9U92EmpoyOApwiv-kyhS7",
      "authorship_tag": "ABX9TyNYaZ4WWGXARBeW9MpjW0BL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rutuja-1462/kaggle-data-pipeline/blob/main/data_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import config\n",
        "\n",
        "def authenticate_kaggle(username, key):\n",
        "    \"\"\"Authenticate with Kaggle using environment variables.\"\"\"\n",
        "    os.environ['KAGGLE_USERNAME'] = username\n",
        "    os.environ['KAGGLE_KEY'] = key\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "    return api\n",
        "\n",
        "def download_dataset(api, dataset_name, download_path):\n",
        "    \"\"\"Download and unzip dataset using Kaggle API.\"\"\"\n",
        "    api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    \"\"\"Load dataset into a Pandas DataFrame.\"\"\"\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "def transform_data(data):\n",
        "    \"\"\"Transform data into dimension and fact tables.\"\"\"\n",
        "    # Product dimension\n",
        "    product_df = data[['Product line', 'Unit price']].drop_duplicates().reset_index(drop=True)\n",
        "    product_df['ProductID'] = product_df.index + 1\n",
        "\n",
        "    # Customer dimension\n",
        "    customer_df = data[['Gender', 'City']].drop_duplicates().reset_index(drop=True)\n",
        "    customer_df['CustomerID'] = customer_df.index + 1\n",
        "\n",
        "    # Fact table\n",
        "    fact_df = data.merge(product_df, on='Product line').merge(customer_df, on=['Gender', 'City'])\n",
        "    fact_df = fact_df[['Invoice ID', 'Date', 'ProductID', 'CustomerID', 'Quantity', 'Total']]\n",
        "\n",
        "    return product_df, customer_df, fact_df\n",
        "\n",
        "def load_to_sqlite(conn, product_df, customer_df, fact_df):\n",
        "    \"\"\"Load data into SQLite database.\"\"\"\n",
        "    product_df.to_sql('Product_Dimension', conn, if_exists='replace', index=False)\n",
        "    customer_df.to_sql('Customer_Dimension', conn, if_exists='replace', index=False)\n",
        "    fact_df.to_sql('Sales_Fact', conn, if_exists='replace', index=False)\n",
        "\n",
        "def query_total_sales(conn):\n",
        "    \"\"\"Query total sales by product line.\"\"\"\n",
        "    query = \"\"\"\n",
        "    SELECT\n",
        "        p.\"Product line\" AS \"Product Line\",\n",
        "        ROUND(SUM(f.\"Total\"), 2) AS \"Total Sales\"\n",
        "    FROM\n",
        "        Sales_Fact f\n",
        "    JOIN\n",
        "        Product_Dimension p\n",
        "    ON\n",
        "        f.\"ProductID\" = p.\"ProductID\"\n",
        "    GROUP BY\n",
        "        p.\"Product line\"\n",
        "    ORDER BY\n",
        "        \"Total Sales\" DESC;\n",
        "    \"\"\"\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "def fetch_table_sample(conn, table_name, limit=5):\n",
        "    \"\"\"Fetch sample rows from a specific table.\"\"\"\n",
        "    query = f\"SELECT * FROM {table_name} LIMIT {limit};\"\n",
        "    return pd.read_sql_query(query, conn)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to execute the workflow.\"\"\"\n",
        "    # Authenticate with Kaggle\n",
        "    api = authenticate_kaggle(config.USERNAME, config.PASSWORD)\n",
        "\n",
        "    # Download and load dataset\n",
        "    dataset_name = 'aungpyaeap/supermarket-sales'\n",
        "    download_path = './data'\n",
        "    download_dataset(api, dataset_name, download_path)\n",
        "\n",
        "    data = load_dataset(f'{download_path}/supermarket_sales - Sheet1.csv')\n",
        "\n",
        "    # Transform data\n",
        "    product_df, customer_df, fact_df = transform_data(data)\n",
        "\n",
        "    # Load data into SQLite\n",
        "    with sqlite3.connect('sales_data.db') as conn:\n",
        "        load_to_sqlite(conn, product_df, customer_df, fact_df)\n",
        "\n",
        "        # Query example\n",
        "        sales_summary = query_total_sales(conn)\n",
        "        print(\"Total Sales by Product Line:\")\n",
        "        print(sales_summary)\n",
        "\n",
        "        # Fetch sample data from a table\n",
        "        sample_data = fetch_table_sample(conn, 'Product_Dimension')\n",
        "        print(\"Sample data from Product_Dimension:\")\n",
        "        print(sample_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "ynxe33HIX_YN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}